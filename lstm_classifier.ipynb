{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7eqcVvLETnJK"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Inusette/Identifying-depression.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install contractions"
      ],
      "metadata": {
        "id": "7_FkSjfMU73Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import bigrams, trigrams\n",
        "\n",
        "import re, string, random\n",
        "import contractions\n",
        "\n",
        "import itertools\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw_PL-srUtoE",
        "outputId": "0375e91c-64aa-4e33-8c83-bccdca4ee508"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_set = stopwords.words(\"english\")\n",
        "# add_custom = [\"add new words\"]"
      ],
      "metadata": {
        "id": "u22ubhcsU1cY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dep_data_path = \"./Identifying-depression/Data_Collector/reddit_depression/\"\n",
        "non_dep_data_path = \"./Identifying-depression/Data_Collector/reddit_non_depression/\"\n",
        "\n",
        "dep_txt_list = os.listdir(dep_data_path)\n",
        "non_dep_txt_list = os.listdir(non_dep_data_path)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 16\n"
      ],
      "metadata": {
        "id": "y4X7gdgXU111"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "stemming = False #reduce the words to their root form\n",
        "\n",
        "def sentence_preprocess(sentence):\n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "    Decontract the words in given sentence, and remove stopwords, URLs, and punctuations\n",
        "    Also, reduce the words to their root form, if applicable \n",
        "\n",
        "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "    extend_sentence = contractions.fix(sentence)\n",
        "    token_words = word_tokenize(extend_sentence)\n",
        "    # rm_stop_words = [word for word in token_words if not word.lower in stopwords_set]\n",
        "    \n",
        "    if stemming == True:\n",
        "        filtered_words = [porter.stem(word) for word in token_words if word.lower() not in stopwords_set]\n",
        " \n",
        "    else:\n",
        "        filtered_words = [word.lower() for word in token_words if word.lower() not in stopwords_set]\n",
        "\n",
        "    sentence = re.sub(r'http\\S+', '', \" \".join(filtered_words)) #remove url\n",
        "    sentence = re.sub(r'[^\\w\\s]', '', sentence) #remove puntuation\n",
        "    sentence = sentence.replace(\"  \",\" \")\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "DcYPws3TU133"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    corpus_tokenized = []\n",
        "    for document in corpus:\n",
        "        corpus_tokenized.append(document.split(\" \"))\n",
        "    return corpus_tokenized\n",
        "\n",
        "def get_vocab(corpus):\n",
        "    vocab = set()\n",
        "    for document in tokenize(corpus):\n",
        "        for word in document:\n",
        "            vocab.add(word)\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "BAWLBp6LU16J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dep_txt_read = []\n",
        "non_dep_txt_read = []\n",
        "for txt_file in dep_txt_list:\n",
        "    with open(dep_data_path+txt_file) as f:\n",
        "        txt_sample =[line.strip() for line in f.readlines()]\n",
        "    dep_txt_read.append(\" \".join(txt_sample))\n",
        "    \n",
        "for txt_file in non_dep_txt_list:\n",
        "    with open(non_dep_data_path+txt_file) as f:\n",
        "        txt_sample =[line.strip() for line in f.readlines()]\n",
        "    non_dep_txt_read.append(\" \".join(txt_sample))\n",
        "\n",
        "dep_processed_data = []\n",
        "non_dep_processed_data = []\n",
        "\n",
        "for sentence in dep_txt_read:\n",
        "    dep_processed_data.append(sentence_preprocess(sentence))\n",
        "    \n",
        "for sentence in non_dep_txt_read:\n",
        "    non_dep_processed_data.append(sentence_preprocess(sentence))\n",
        "\n",
        "print(f\"# of dep posts: {len(dep_processed_data)}\")\n",
        "print(f\"# of non-dep posts: {len(non_dep_processed_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3nEgLQvU1-K",
        "outputId": "9260f70c-bf14-4a88-96eb-6cf09571806f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of dep posts: 1293\n",
            "# of non-dep posts: 548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'text': dep_processed_data + non_dep_processed_data,\n",
        "     'class': [1 for i in range(len(dep_processed_data))] + [0 for i in range(len(non_dep_processed_data))]}\n",
        "df = pd.DataFrame(data=d)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gxi76yIoU2Ad",
        "outputId": "0a56b72a-e3f7-479e-cfe8-c24bb79a9bba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  class\n",
              "0  exercise make feel better everyone says listen...      1\n",
              "1                      anyone talk time trying stop       1\n",
              "2  carpe diem today day change sick tire letting ...      1\n",
              "3  today going tough okay bit really slump couple...      1\n",
              "4  even want talk anymore ever say word would reg...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8172f9e-2854-48fc-bcf4-bc45471d44f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exercise make feel better everyone says listen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anyone talk time trying stop</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>carpe diem today day change sick tire letting ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today going tough okay bit really slump couple...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>even want talk anymore ever say word would reg...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8172f9e-2854-48fc-bcf4-bc45471d44f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8172f9e-2854-48fc-bcf4-bc45471d44f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8172f9e-2854-48fc-bcf4-bc45471d44f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "PADDING_VALUE = 0\n",
        "UNK_VALUE     = 1\n",
        "\n",
        "def split_train_val_test(df, props=[.8, .1, .1]):\n",
        "    assert round(sum(props), 2) == 1 and len(props) >= 2\n",
        "    train_df, test_df, val_df = None, None, None\n",
        "    \n",
        "    train_idx = int(len(df)*props[0])\n",
        "    valid_idx = int(len(df)*(props[0]+props[1]))\n",
        "\n",
        "    train_df = df.iloc[:train_idx]\n",
        "    val_df = df.iloc[train_idx:valid_idx]\n",
        "    test_df = df.iloc[valid_idx:]  \n",
        "    \n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def generate_vocab_map(df, cutoff=2):\n",
        "    vocab          = {\"\": PADDING_VALUE, \"UNK\": UNK_VALUE}\n",
        "    reversed_vocab = None\n",
        "\n",
        "    word_count = Counter()\n",
        "    for row in df['tokenized']:\n",
        "      word_count += Counter(row)\n",
        "\n",
        "    unique_id = len(vocab)\n",
        "    for word, count in word_count.items():\n",
        "      if count > cutoff:\n",
        "        vocab[word] = unique_id\n",
        "        unique_id += 1\n",
        "\n",
        "    reversed_vocab = dict()\n",
        "    for word, unique_id in vocab.items():\n",
        "      reversed_vocab[unique_id] = word\n",
        "\n",
        "    return vocab, reversed_vocab"
      ],
      "metadata": {
        "id": "9THz7e-eU2CY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"tokenized\"] = df[\"text\"].apply(lambda x: nltk.word_tokenize(x.lower()))\n",
        "\n",
        "df                         = df.sample(frac=1) # random shuffling\n",
        "train_df, val_df, test_df  = split_train_val_test(df, props=[.8, .1, .1])\n",
        "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
      ],
      "metadata": {
        "id": "r-hu104UdV0X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "corpus = train_df[\"text\"]\n",
        "pipe = Pipeline([('count', CountVectorizer(ngram_range=(1, 2), max_features=6000)),\n",
        "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
        "# print(pipe['count'].transform(corpus).toarray().shape)\n",
        "# print(pipe['tfid'].idf_)\n",
        "# print(pipe.transform(corpus).shape)"
      ],
      "metadata": {
        "id": "D-wXg1FtuDfY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"ngram\"] = train_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])\n",
        "val_df[\"ngram\"] = val_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])\n",
        "test_df[\"ngram\"] = test_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoBgfdT3u-lj",
        "outputId": "5c722d05-5014-40b6-961f-b213c7200a36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-10e57b67b880>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df[\"ngram\"] = train_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])\n",
            "<ipython-input-11-10e57b67b880>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  val_df[\"ngram\"] = val_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])\n",
            "<ipython-input-11-10e57b67b880>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df[\"ngram\"] = test_df[\"text\"].apply(lambda x: pipe.transform([x]).toarray()[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class HeadlineDataset(Dataset):    \n",
        "    def __init__(self, vocab, df, max_length=50):\n",
        "        self.vocab = vocab\n",
        "        self.df = df\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        df_len = len(self.df)\n",
        "\n",
        "        return df_len\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        tokenized_word_tensor = list()\n",
        "\n",
        "        for word in self.df.iloc[index][\"tokenized\"]:\n",
        "          encoded_word = train_vocab.get(word) if train_vocab.get(word) != None else train_vocab.get(\"UNK\")\n",
        "          tokenized_word_tensor.append(encoded_word)\n",
        "\n",
        "        tokenized_word_tensor = torch.LongTensor(tokenized_word_tensor[:self.max_length])\n",
        "        curr_label = self.df.iloc[index][\"class\"]\n",
        "        ngram_feature = self.df.iloc[index][\"ngram\"]\n",
        "\n",
        "        return (tokenized_word_tensor,ngram_feature), curr_label"
      ],
      "metadata": {
        "id": "svAOEcQrdMIi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import RandomSampler, DataLoader\n",
        "\n",
        "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
        "    \n",
        "    padded_tokens = [torch.LongTensor([PADDING_VALUE]*50)]\n",
        "    ngram_features = []\n",
        "    y_labels = []\n",
        "    for row in batch:\n",
        "      word_tensor, curr_label = row\n",
        "      padded_tokens.append(word_tensor[0])\n",
        "      ngram_features.append(word_tensor[1])\n",
        "      y_labels.append(curr_label)\n",
        "    \n",
        "    padded_tokens = pad_sequence(padded_tokens,batch_first=True,padding_value=PADDING_VALUE)[1:]\n",
        "    ngram_features = torch.FloatTensor(np.array(ngram_features))\n",
        "    y_labels = torch.FloatTensor(y_labels)\n",
        "\n",
        "    return (padded_tokens,ngram_features), y_labels\n",
        "\n",
        "train_dataset = HeadlineDataset(train_vocab, train_df)\n",
        "val_dataset   = HeadlineDataset(train_vocab, val_df)\n",
        "test_dataset  = HeadlineDataset(train_vocab, test_df)\n",
        "\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "val_sampler   = RandomSampler(val_dataset)\n",
        "test_sampler  = RandomSampler(test_dataset)\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
        "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
        "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "5Jz6b8wceW9S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true, pred):\n",
        "    incorrect_ratio = float(torch.sum((true*1 + pred*1==1))/len(true))\n",
        "    acc = 1 - incorrect_ratio\n",
        "    return acc"
      ],
      "metadata": {
        "id": "9b3ZFg8QQFSU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, criterion, optim, iterator):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(iterator):\n",
        "        words, ngram = x\n",
        "        optim.zero_grad()\n",
        "        prediction = torch.squeeze(model(words.to(device), ngram.to(device)))\n",
        "        loss = criterion(prediction, y.to(device))\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        total_loss += loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def val_loop(model, iterator):\n",
        "    true, pred = [], []\n",
        "    model.eval()\n",
        "    for x, y in iterator:\n",
        "        words, ngram = x\n",
        "        prediction = torch.squeeze(model(words.to(device), ngram.to(device))).detach().cpu()\n",
        "        pred.append(prediction)\n",
        "        true.append(y)\n",
        "    \n",
        "    true = torch.hstack(true) >= 0.5\n",
        "    pred = torch.hstack(pred) >= 0.5\n",
        "    \n",
        "    return true, pred"
      ],
      "metadata": {
        "id": "m9fZU-pse7j5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \\\n",
        "                 num_layers=1, bidirectional=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=hidden_dim,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
        "\n",
        "        self.fc_lstm = nn.Linear(hidden_dim*(bidirectional+1),256)\n",
        "\n",
        "        self.fc1_ngrm = nn.Linear(6000,512)\n",
        "        self.fc2_ngrm = nn.Linear(512,128)\n",
        "\n",
        "        self.fc_final = nn.Linear(256+128,1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, words, ngram):\n",
        "\n",
        "        word_embeddings = self.lstm_embedding(words)\n",
        "        out, hidden = self.lstm(word_embeddings)\n",
        "        lstm_out = self.fc_lstm(out[:,-1,:])\n",
        "        ngrm_out = self.fc2_ngrm(self.relu(self.fc1_ngrm(ngram)))\n",
        "\n",
        "        final_out = self.fc_final(torch.cat((lstm_out,ngrm_out), dim=-1))\n",
        "        pred_score = self.sigmoid(final_out)\n",
        "\n",
        "        return pred_score"
      ],
      "metadata": {
        "id": "sVrV5e0XNoUE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "model = LSTM(vocab_size=len(train_vocab.keys()), embedding_dim=256, hidden_dim=256, num_layers=1, bidirectional=True).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr = 1e-4)"
      ],
      "metadata": {
        "id": "eNteTdgLNq1V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_EPOCHS = 5\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_loss = train_loop(model, criterion, optimizer, train_iterator)\n",
        "    true, pred = val_loop(model, val_iterator)\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    print(f\"TRAIN LOSS: {train_loss}\")\n",
        "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzupFHiteXG0",
        "outputId": "1d80d6ee-bc8c-486b-f547-8bc10dfbf2fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:03<00:00, 24.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n",
            "TRAIN LOSS: 55.50115966796875\n",
            "VAL ACC: 0.695652186870575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:02<00:00, 35.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n",
            "TRAIN LOSS: 46.935935974121094\n",
            "VAL ACC: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:02<00:00, 30.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 2\n",
            "TRAIN LOSS: 27.417816162109375\n",
            "VAL ACC: 0.8913043513894081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 64.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 3\n",
            "TRAIN LOSS: 11.725215911865234\n",
            "VAL ACC: 0.9293478280305862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 72.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 4\n",
            "TRAIN LOSS: 5.549252510070801\n",
            "VAL ACC: 0.9239130467176437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 72.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 5\n",
            "TRAIN LOSS: 2.949536085128784\n",
            "VAL ACC: 0.9130434766411781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 75.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 6\n",
            "TRAIN LOSS: 1.8431024551391602\n",
            "VAL ACC: 0.9184782579541206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 74.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 7\n",
            "TRAIN LOSS: 1.2072057723999023\n",
            "VAL ACC: 0.9184782579541206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 76.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 8\n",
            "TRAIN LOSS: 0.8619803190231323\n",
            "VAL ACC: 0.9184782579541206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 92/92 [00:01<00:00, 74.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 9\n",
            "TRAIN LOSS: 0.6663330793380737\n",
            "VAL ACC: 0.9184782579541206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "PxCl9uEtj8bM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See how your model does on the held out data\n",
        "true, pred = val_loop(model, test_iterator)\n",
        "print(f\"TEST ACC: {accuracy(true, pred)}\")\n",
        "\n",
        "print(\"Precision\", precision_score(true, pred))\n",
        "print(\"Recall\", recall_score(true, pred))\n",
        "print(\"F1\", f1_score(true, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3PNGcXse-90",
        "outputId": "7a4a0054-1b6f-4730-8055-10d4d5998b31"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST ACC: 0.9459459446370602\n",
            "Precision 0.9465648854961832\n",
            "Recall 0.9763779527559056\n",
            "F1 0.9612403100775194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM (w/unigram and bigram)\n",
        "# TEST ACC: 0.9459459446370602\n",
        "# Precision 0.9465648854961832\n",
        "# Recall 0.9763779527559056\n",
        "# F1 0.9612403100775194"
      ],
      "metadata": {
        "id": "Bi9fJNXOk0zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM (base)\n",
        "# TEST ACC: 0.9027027040719986\n",
        "# Precision 0.9253731343283582\n",
        "# Recall 0.9393939393939394\n",
        "# F1 0.9323308270676692"
      ],
      "metadata": {
        "id": "LlFyMx7qe_XN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}